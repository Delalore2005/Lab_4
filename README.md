# LAB_4 — Кластеризация данных Airbnb

## Обзор
Этот отчёт суммирует полный цикл обработки объявлений Airbnb по Нью-Йорку за 2019 год: поиск и визуализацию проблемных данных в R, очистку и подготовку признаков, масштабирование в Python и сравнение четырёх алгоритмов кластеризации (включая собственную реализацию K-means). Для воспроизводимости доступна Docker-среда и архив контейнера.

## Состав репозитория
- `r_scripts/cleaning_airbnb.ipynb` — поиск пропусков, дубликатов и выбросов, первичный анализ и визуализация очищенных данных в R.
- `py_scripts/airbnb_clustering.py.ipynb` — масштабирование признаков, кластеризация (включая собственный K-means) и визуализация в Python.
- `images/` — экспортированные графики из ноутбуков (распределения, масштабирование, кластеры и др.).
- `docker-compose.yml` — окружение c Jupyter Notebook и RStudio.
- `docker_container.zip` — архив с контейнером и исходной структурой проекта.

> Очищенный датасет (`data/airbnb_clean.csv`) упоминается в ноутбуках, но не включён в репозиторий.

## Отчёт
### 1. Проблемные данные (R)
- В `cleaning_airbnb.ipynb` визуализированы пропуски (`last_review`, `reviews_per_month`) через матрицу пропусков и сводные таблицы, а также частоты дубликатов и выбросов.
- Обнаружены и удалены 252 дубликата; пропуски в `reviews_per_month` заменены на 0, строки с некорректной ценой (≤0) или экстремумами (>500) отфильтрованы.

### 2. Выводы по исходному датасету
- Стартовый объём — 48 895 записей с сильной правосторонней асимметрией цен и редкими, но значимыми выбросами по `minimum_nights` и `number_of_reviews`.
- После очистки осталось 47 640 строк; удалены неинформативные поля (`id`, `name`, `host_name`, `last_review`), числовые признаки приведены к устойчивым границам по IQR.

### 3. Визуализация после очистки (R)
- Распределение цен после фильтрации аномалий — `images/price_distribution.png`.
- Boxplot основных числовых признаков после очистки — `images/numeric_features_boxplot.png`.

### 4. Масштабирование и нормализация (Python)
- Для подготовки к кластеризации применяется `StandardScaler`; сравнение распределений цены до/после масштабирования — `images/price_scaling_comparison.png`.
- Масштабирование устраняет доминирование признаков с крупными значениями в метрике расстояния и стабилизирует обучение моделей.

### 5. Визуализация кластеризаций
Алгоритмы обучены на масштабированных признаках, для отображения использована PCA до 2 компонент:
- Собственная реализация **K-Means** — `images/kmeans_custom.png`.
- **K-Means (scikit-learn)** — `images/kmeans_sklearn.png`.
- **Agglomerative Clustering** — `images/agglomerative_clustering.png`.
- **Gaussian Mixture Model (GMM)** — `images/gaussian_mixture.png`.

### 6. Выводы по кластеризации
- Метрика силуэта: K-Means (custom) 0.3513, K-Means (sklearn) 0.3513, GMM 0.3795, Agglomerative 0.3018.
- Кластеры интерпретируются как сочетания доступности и ценового уровня: от низких цен и высокой доступности до премиальных объявлений с ограниченной доступностью и большим числом отзывов.
- GMM показал наилучший силуэт, но K-Means остаётся интерпретируемой базовой моделью; Agglomerative хуже разделяет данные из-за чувствительности к масштабам и форме кластеров.

### 7. ZIP-архив контейнера
`docker_container.zip` включает `docker-compose.yml`, каталоги `r_scripts/` и `py_scripts/`, а также сопутствующие файлы для поднятия окружения локально. Разверните архив и выполните:
```bash
docker-compose up -d
```
Доступные сервисы: Jupyter Notebook (порт 8888, токен в логах) и RStudio (порт 8787, пароль `password`).

## Локальный запуск без архива
1. Установите Docker и Docker Compose.
2. Запустите сервисы: `docker-compose up -d`.
3. Откройте в браузере интерфейс RStudio (порт 8787) или Jupyter (порт 8888) и работайте с ноутбуками из `r_scripts/` и `py_scripts/`.

